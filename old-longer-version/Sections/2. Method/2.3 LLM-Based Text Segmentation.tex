% 2. Method

\subsection{LLM-Based Text Segmentation}\label{LLM-Based Text Segmentation}

% 2.3 LLM-Based Text Segmentation

How can we get LLMs to output segment boundaries?

We might first consider passing in the input text as a prompt and asking the LLM to copy out the text, adding markers indicating where it has placed boundaries as is suggested by~\citep{XingThesis}. However, not only is this wasteful of tokens, especially if the input text is long, but crucially, the LLM may fail to copy the input accurately, may change the formatting, and we found through qualitative experimentation that boundary placement was not any better than our final method. These problems are addressed by~\citep{XingThesis} through repeated prompting until the input and output sequence lengths match but this provides no guarantees. In our use case, guaranteeing that the input data would remain the same was essential so we opted for a different prompting strategy.

\subsubsection{Prompting Method}

We first annotate the text with indices between each sentence. Here is an example: `Hello World. [1] The sky is blue. [2] The sun is is yellow. [3] The grass is green. [4] Machine learning is a rapidly evolving field'. We then ask the LLM to return a list of indices corresponding to boundaries. In the previous example, the ideal response might be `1,4'. In practice, the texts and list of segment boundaries are much longer.

We add a system prompt which describes the segmentation task, desired output format and primes the model to be a talented linguist. We also add a variety of short examples in line with the few-shot prompting technique~\citep{FewShotLearners} which improved performance. This did not necessarily reflect the fact that the LLM learned how to segment better. Instead, through manual testing, we suspect that it learned the ideal segment length and amount of information that should be contained within a segment, which was implicitly contained in the few-shot prompt (and also the testing datasets, therefore increasing performance). This suggests that different implicit definitions of a segment could be imposed by a few-shot prompt to a LLM, dependent upon use case.

An example prompt can be found in Appendix~\ref{Prompting Strategy}.

\subsubsection{Overlapping Prompts}

A limitation also identified by~\cite{XingThesis} is that ChatGPT's segmentations were limited to the context window of the model. While our prompting strategy uses fewer tokens as the model need not copy out the input text, the same limitation applies. Therefore, we propose a simple overlapping prompt strategy to overcome this limitation.

Our prompting method works so long as the input text is within the context window of the LLM. At the time of experimentation, and with the use of gpt-3.5-turbo, we had a limit of 16k tokens. Many of our input texts exceeded this limit. Therefore, we need to split up these long documents into smaller chunks that can be processed by the LLM. However, this cannot be done by simply splitting the text at the nearest sentence before every 16k new tokens for two reasons. First, we do not know whether this sentence boundary should serve as a segment boundary. Second, the LLM loses valuable context which helps to choose where to place boundaries at the extremes of the 16k tokens.

Therefore, we instead send 16k prompts with some overlap. The overlap is calculated as twice the maximum segment length. In our experiments, we set a maximum segment length of 750 tokens, thus there is an overlap of 1500 tokens between prompts. We must then decide which boundaries to accept in this overlapping region. Given two generations which were prompted by 1500 overlapping tokens, we choose to accept the segment boundaries contained within the first 750 tokens of the overlapping section from the first generations and the boundaries in the final 750 tokens from the second prompt. We did not experiment with involving the responses from both outputs, but found no sign of worse performance towards segment boundaries.

While this method is wasteful of up to 1500 tokens per prompt, this is a small enough fraction of the 16k context that we were satisfied with the solution. If maximum segment lengths were much longer, the context may need to be limited more severely.

\subsubsection{Segment Validation}

We also performed some validation on the segments returned by the LLM. This primarily involved verifying that the returned segments are within a maximum and minimum segment length. Segments that are too short (for example, a model would sometimes return just a heading) were concatenated with another segment and segments that are too long were recursively segmented by the same model. This recursive segmentation was done with another prompt that asks the model to generate only one boundary. Again, we use a few-shot prompting strategy. This way, a segment that is too long will be split in two recursively until all segments are within the specified lengths.