% 4. Conclusion

Our work empirically compares generative LLMs with previous methods which use BERT embeddings and cosine similarity. In order to be more token-efficient and to provide guarantees that the original document will be unaltered, we propose a new overlapping prompt schema which centres on asking the LLM to return a list of indices corresponding to segment boundaries. We also support the use of boundary similarity and its associated information recall metrics as an evaluation for topic segmentation. Results indicate that LLMs can be more effective segmenters than existing methods where more nuanced segmentations are required. On the contrary, when the input is noisy or the segment boundaries are clear BERT-based methods are more reliable. Future work should focus on addressing highlighted issues with LLMs such as the regular patterns found in segmentations and conduct a more thorough comparison of different prompting methods or loss-based approaches. Lastly, larger human-annotated datasets of a range of media should be constructed to better assess generalisation capabilities.