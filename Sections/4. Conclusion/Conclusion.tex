% 4. Conclusion

Our work empirically compares generative LLMs with methods which use BERT embeddings and cosine similarity for topic segmentations. We propose a new overlapping prompting method that is token-efficient and provides guarantees of the integrity of the data passed into the model. We also support the use of boundary similarity and its associated information recall metrics for evaluation. Results indicate that LLMs can be more effective segmenters where more nuanced segmentations are required. On the contrary, when the input is noisy or the segment boundaries are clear, BERT-based methods may be more reliable. Future work should involve a thorough comparison of different prompting methods and addressing highlighted issues with LLM outputs using our method. Lastly, larger human-annotated datasets should be constructed to better assess generalisation capabilities.