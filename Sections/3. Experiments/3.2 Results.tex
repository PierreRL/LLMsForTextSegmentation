% 3.2 Results

\subsection{Quantitative Results}

Models were tested on \emph{Human}, \emph{Wiki}, \emph{Conc-Wiki} and a test-partition of \emph{Synthetic}. We do not base our conclusions on results from \emph{Synthetic} as they would be biased in favor of the generative models which generated the segmentations. We evaluate using the previously discussed boundary similarity~\ref{evaluation} with $n=2$ as the metric becomes noisier with higher values of $n$. Results can be seen in Table~\ref{tab:combined_results}.

Due to resource constraints, we could not test \emph{GPT3.5} on the full \emph{Wiki} or \emph{Conc-Wiki} datasets. Instead, we took the largest subset that fit within resource constraints. We evaluated all other models on the full datasets to verify that comparable results are obtained. Full results on all evalutation metrics can be found at the following links for both the \href{https://docs.google.com/spreadsheets/d/e/2PACX-1vT3XnZ-npYMquwabYd_WGZrvFLtNDTsN-qwp94-kKR4M6Fq0Y0f87a6P0RNQ_W1VvGJtE_kPI5conlA/pubhtml}{smaller} and \href{https://docs.google.com/spreadsheets/d/e/2PACX-1vTPqglQkIVhni9NzkKeJUG_IYywFUFc1vNBK0j_TSDoK1S_WBkkgSlrRQ-xagjN44dVeAI8IU7krrLt/pubhtml}{full} dataset.

We see that \emph{GPT3.5} outperforms all other models on \emph{Human},\emph{Wiki}, and \emph{Synthetic}, with the other LLM, \emph{FlanT5}, coming in second in the same datasets. The close performance between the models on \emph{Synthetic} implies that \emph{FlanT5} is a good approximation of \emph{GPT3.5} for this task, on boundaries generated by \emph{GPT3.5}. The biggest performance gap between the two is on \emph{Human}. Although this dataset is small, it represents a meaningful distribution shift and the smaller fine-tuned model is unable to generalize as well as the base model.

Interestingly, we see that both BERT-based models are superior in the supposedly easier task posed by \emph{Conc-Wiki}. We theorise that these models are better at finding clear boundaries between different domains but struggle with more nuanced segment boundaries found in news articles, for example. By contrast, the LLMs are better at finding more nuanced segments that a human might have produced but are not significantly better at finding more clear-cut boundaries.

We also looked at precision and recall to better characterise the behavior of each model. \emph{GPT3.5} has the highest precision and recall on \emph{Human} and the highest recall on both \emph{Wiki} and \emph{Conc-Wiki}. This high recall is true in general for the LLMs, even on \emph{Conc-Wiki} where the BERT models have higher overall boundary similarity. On the other hand, precision scores are generally closer, except on \emph{Conc-Wiki} where they are much better for the BERT models. This suggests that in general the BERT models are more hesitant in placing boundaries, but when they do, they are more likely to be correct. It should be noted that this behaviour in both the LLMs and BERT models is subject to the prompt and segment processing/validation procedures used.

\subsection{Qualitative Evaluation}

Through manual inspection of segmentations on \emph{Human}, we found that \emph{GPT3.5} found boundaries which seemed reasonable from a human perspective, especially for simple documents like short news articles. \emph{FlanT5} model imitated this behavior but was less consistent. BERT segmenters would find reasonable segments, but after the manual gluing and splitting procedure, would often lead to off-by-1 errors and would miss some boundaries.

For documents with more complex or nuanced text or with messy data like tables and artefacts, \emph{GPT3.5} would sometimes return indices with a regular pattern. For example, '$[1,15,22, \ldots, 76, 79, 82, 85, \ldots 118, 121, \ldots]$'. The pattern would often continue far beyond the number of sentences in the input. Better prompt engineering, a more rigorous data-processing procedure, the use of newer models or the use of better generation parameters might help. However, our current approach was resource constrained but still required the ability to pass noisy documents to the model. A more thorough investigation of the logits computed by the model is required to understand how and when this occurs, and how to mitigate it. 