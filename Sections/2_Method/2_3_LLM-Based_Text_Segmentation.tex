% 2.3 LLM-Based Text Segmentation
\subsection{LLM-Based Text Segmentation}\label{LLM-Based Text Segmentation}

How can we get LLMs to output segment boundaries? We might consider prompting with the input text and asking the LLM to add characters delimiting boundaries~\citep{XingThesis}. However, not only is this wasteful of tokens, but the LLM may fail to copy the input perfectly. These problems are addressed by~\citep{XingThesis} through repeated prompting until sequence lengths match, but this provides no guarantees. Our use case requires a guarantee that the input data would be unedited, so we opt for a different prompting strategy. The method is illustrated in Figure~\ref{fig:diagram} and is described below.

We first annotate the text with indices between each sentence. As an example: `Hello World. [1] The sky is blue. [2] The sun is is yellow'. We then ask the LLM to return a list of indices corresponding to boundaries. In the previous example, the ideal response might be `1'. We add a system prompt which describes the segmentation task, desired output format and primes the model for segmentation, exemplified in Appendix~\ref{Prompting Strategy}. We also add a variety of examples in line with the few-shot prompting technique~\citep{FewShotLearners}. 

% This did not necessarily reflect the fact that the LLM learned how to segment better. Instead, through manual testing, we suspect that it learned the ideal segment length and amount of information that should be contained within a segment, which was implicitly contained in the few-shot prompt (and also the testing datasets, therefore increasing performance). This suggests that different implicit definitions of a segment could be imposed by a few-shot prompt to an LLM.

Many of our input documents exceeded the context window of models available at the time. Therefore, we propose a simple overlapping prompt strategy to overcome this limitation. This should not be done by splitting the text at the sentence nearest to the context window limit for two reasons. First, we do not know whether this sentence boundary should serve as a segment boundary. Second, the LLM loses valuable context which helps to choose where to place boundaries at the extremes. Therefore, we send prompts with some overlap between sections. We choose an overlap of twice the maximum segment length. In our experiments, we set a maximum segment length of 750 tokens and hence an overlap of 1500 tokens. Given two generations which were prompted by 1500 overlapping tokens, we accept boundaries for the first 750 tokens from the first prompt and the boundaries in the final 750 tokens from the second. 

% Our prompting method works so long as the input text is within the context window of the LLM. At the time of experimentation, and with the use of gpt-3.5-turbo, we had a limit of 16k tokens. Many of our input texts exceeded this limit. Therefore, we need to split up these long documents into smaller chunks that can be processed by the LLM.



% We did not experiment with involving the responses from both outputs, but found no sign of worse performance towards segment boundaries.

% While this method is wasteful of up to 1500 tokens per prompt, this is a small enough fraction of the 16k context that we were satisfied with the solution. If maximum segment lengths were much longer, the context may need to be limited more severely.

We also perform validation on the segments returned by the LLM. We first verify that the returned segments are of an appropriate length. Segments that are too short are concatenated with a neighbouring segment and segments that are too long are recursively segmented by the same model. Recursive segmentation was done with another prompt that asks the model to generate a single boundary. Again, we use a few-shot prompting strategy. We choose a minimum segment length of 50 words and a maximum of 500 words.