% 2. Method
% 2.1 Datasets
\subsection{Datasets}

There are 4 datasets used in the experiments in this work: a small human-annotated dataset, a scrape of English wikipedia, a 'concatenated' wikipedia scrape and a synthetic GPT3.5 generated dataset.

\subsubsection{Human-Annotated Dataset}

Lacking the resources to create a large dataset annotated by humans, this work uses a very small manually segmented dataset of 10 documents. These documents are a mix of news articles, wikipedia articles, and miscellaneous documents such as podcast transcripts and scientific reports. This was intended to represent varying difficulties of segmentation, and provide examples which could be manually inspected to interpret segmenter behaviour. Only one annotator was used, and the segments were created by hand. Further work might involve multiple annotators on a much larger dataset, with a more rigorous process to ensure consistency and quality.

\subsubsection{Wikipedia Dataset}

A plain text English wikipedia scrape\footnote{\url{https://www.kaggle.com/datasets/ltcmdrdata/plain-text-wikipedia-202011/data}} was used articles where headings were delimited by special characters. The articles were then automatically segmented based on headings, and filtered to remove articles with very few segments, too short segments, or too much punctuation such as tables and figures. After this process, there remained approximately 1000 segmented articles. We generate two version of this dataset: one with headings removed, and one with headings included. We evaluate models on both versions of the dataset, but include only the version with headings removed in the final results.

\subsubsection{Concatenated Wikipedia Dataset}

We randomly sampled segments from the previous Wikipedia dataset and concatenated them in order to form new incoherent articles, with segments drawn from completely different domains. Intuitively, this dataset should be easier to segment as there are no semantic links between segments.

\subsubsection{Synthetic Dataset}

The final dataset used was generated synthetically by GPT-3.5. The source data was a mix of CTC sentinel data\footnote{\url{https://ctc.westpoint.edu/ctc-sentinel/}}, UN-Peacekeeping corpus\footnote{\url{https://peacekeeping.un.org/en/reports}} and an internal dataset at Adarga. These documents were segmented by querying OpenAI's API with the model \texttt{gpt-3.5-turbo-16k} using the overlapping prompt schema defined in section~\ref{LLM-Based Text Segmentation}. This dataset was exclusively used for fine-tuning the \emph{FlanT5}\ref{FlanT5} model. It was not used for evaluation as the results would be biased in favor of the generative models.