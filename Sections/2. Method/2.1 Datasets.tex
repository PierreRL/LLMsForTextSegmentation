% 2. Method
% 2.1 Datasets
\subsection{Datasets}

There are 4 datasets used in the experiments in this work: a small human-annotated dataset, a scrape of English wikipedia, a `concatenated' wikipedia scrape and a synthetic GPT3.5 generated dataset.

\subsubsection{Human-Annotated Dataset}

Lacking the resources to create a large dataset annotated by humans, this work uses a small dataset of 10 documents which was manually segmented. These documents are a mix of news articles, wikipedia articles, and miscellaneous documents such as podcast transcripts and scientific reports. This was intended to represent varying difficulties of segmentation and to provide examples which could be manually inspected to interpret segmenter behaviour. Only one annotator was used and the segments were created by hand. While these documents were long and the documents were segmented with care, further work should involve multiple annotators on a much larger dataset to ensure consistench and reliability.

\subsubsection{Wikipedia Dataset}

A plain text English wikipedia scrape\footnote{\url{https://www.kaggle.com/datasets/ltcmdrdata/plain-text-wikipedia-202011/data}} where headings are delimited by special characters was employed in our experiments. The articles were then automatically segmented based on these headings and filtered to remove articles with very few segments, too short segments, or too many artefacts such as tables and figures. After this process, there remained approximately 1000 segmented articles. We generate two versions of this dataset: one with headings removed, and one with headings included. We evaluate models on both versions of the dataset, but include only the version with headings removed in the final results.

\subsubsection{Concatenated Wikipedia Dataset}

We randomly sampled segments from the previous Wikipedia dataset and concatenated them in order to form new incoherent articles, with segments drawn from completely different domains. Intuitively, this dataset should be easier to segment as there are no semantic links between segments.

\subsubsection{Synthetic Dataset}

The final dataset was generated synthetically by GPT-3.5. The source data was a mix of CTC sentinel data\footnote{\url{https://ctc.westpoint.edu/ctc-sentinel/}}, UN-Peacekeeping corpus\footnote{\url{https://peacekeeping.un.org/en/reports}} and an internal dataset at Adarga. These documents were segmented by querying OpenAI's API with the model \texttt{gpt-3.5-turbo-16k} using the overlapping prompt schema defined in section~\ref{LLM-Based Text Segmentation}. This dataset was used exclusively for fine-tuning the \emph{FlanT5} (\ref{FlanT5}) model. It was not used for evaluation as the results would be biased in favour of the generative models which generated or were trained on the data.