% 2. Method

\subsection{LLM-Based Text Segmentation}\label{LLM-Based Text Segmentation}

% 2.3 LLM-Based Text Segmentation

How can we get LLMs to output segment boundaries?

We might first consider passing in the input text as a prompt and asking the LLM to copy out the text, adding markers indicating where it has placed boundaries as is suggested by \cite{XingThesis}. However, not only is this wasteful of tokens, especially if the input text is long, but crucially, the GLM may fail to copy the input accurately, may change the formatting, and we found through qualitative experimentation that boundary placement was not any better than our final method. These problems are addressed by \cite{XingThesis} through repeated prompting until the input and output sequence lengths match, but this still does not guarantee integrity of the data. In our use case, guaranteeing that the input data would remain the same was of the utmost importance, so we used a different strategy.

\subsubsection{Prompting Method}

We first annotate the text with indices between each sentence. For example 'Hello World. [1] The sky is blue. [2] The sun is is yellow. ' We then ask the GLM to return a list of indices corresponding to boundaries. In the previous example, the ideal response might be '1'. In practice, the texts and list of segment boundaries are much longer.

We add a system prompt which describes the segmentation task, desired output format and primes the model to be a talented linguist. We also add a variety of short examples in line with the few shot prompting technique \cite{FewShotLearners}, which increased performance. This did not necessarily reflect the fact that the GLM learnt how to segment better. Instead, through manual testing, we suspect that it learnt the ideal segment length and amount of information that should be contained within a segment, which was implicitly contained in the few shot prompt (and also the testing datasets, therefore increasing performance). This suggests that different implicit definitions of a segment could be imposed by a few shot prompt to a GLM, dependent upon use case.

An example prompt is contained in [XXX Appendix A].

\subsubsection{Overlapping Prompts}

This prompting method works so long as the input text is within the context window of the LLM. At the time of experimentation, and with the use of gpt-3.5-turbo, we had a limit of 16k tokens. Many of our input texts exceeded this limit. Therefore, we needed to split up these long documents into smaller chunks that can be processed by the GLM. However, this cannot be done by simply splitting every at the nearest sentence before every 16k new tokens for two reasons. Firstly, we do not know whether this sentence boundary should serve as a segment boundary, and secondly, the GLM loses valuable context which helps to choose where to place boundaries at the extremes of 16k tokens.

Therefore, we instead send 16k prompts that overlap. The overlap is calculated as twice maximum segment length. In our experiments, we set a maximum segment length of 750 tokens, thus there is an overlap of 1500 tokens between prompts. We must then decide which boundaries to accept in this overlapping region. Given two generations which were prompted by 1500 overlapping tokens, we choose to accept the segment boundaries contained within the first 750 tokens of the overlapping section from the first generation, and the boundaries in the final 750 tokens from the second prompt. We did not experiment with involving the responses from both outputs, but found that there seemed to be no sign of degrading performance towards segment boundaries.

While this method is wasteful of up to 1500 tokens per prompt, this is a small enough fraction of the 16k context that we were satisfied with the solution. If maximum segment lengths were much longer, say 5k tokens, the context may need to be limited more severely.

\subsubsection{Segment Validation}

We also performed some validation on the segments returned by the GLM. This primarily involved verify that the returned segments are within a maximum and minimum segment length. Segments that are too short (for example, a model would often return just a heading), were concatenated with another segment, and segments that are too long were recursively segmented by the same model, but with another prompt that asks the model to generate only one boundary at a time, which uses a similar few-shot prompting strategy to above. This way, a segment that is too long will be split in 2 recursively until all segments are within the specified lengths.