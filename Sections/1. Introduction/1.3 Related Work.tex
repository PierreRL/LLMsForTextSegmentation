\subsection{Related Work}

Please refer to \citep{XingThesis} which provides a recent, broad overview of topic segmentation.

An influential framework introduced by~\citep{TextTiling} involves computing lexical similarity scores between adjacent sentences before boundaries are placed where similarity is lowest~\citep{lexical1,lexical2}. Such a framework is still in use today but with semantic similarity calculated from embeddings. Neural networks have seen use as BiLSTMs ~\citep{BiLSTM,HierarchicalBiLSTM,CNNFeaturesLSTMAttention} and attention-based methods~\cite{CrossAttentionHierarchical,TwoLevelTransformerSoftmax,TwoLevelTransformerPretrained}. However, these models do not leverage the vast knowledge contained in the largest pre-trained models.

LLMs are the state of the art for a variety of NLP tasks. However, there has been little research into their use for topic segmentation. A loss-based approach was proposed by~\citep{DialoGPT} in which boundaries are placed at peaks in the mean negative log likelihood of tokens in a sentence, indicating that the sentence was hard to predict. This method relies on the dubious assumption that all information about segment boundary location can be expressed by the next token prediction loss.

Previous work has explored segmentation by prompting LLMs~\citep{XingThesis}. They find that prompting ChatGPT is the best dialogue segmentation model unless the input exceeds ChatGPT's limit. Two prompting methods are proposed: one which asks the LLM to return the original text with characters delimiting boundaries and a second in which the LLM is asked to return semantic coherence scores for each pair of sentences. The first method does not satisfy a guarantee that the model will return the original document unedited and is massively wasteful of tokens. In the second method, the returned scores have no guarantee of directly corresponding to semantic coherence specifically for topic segmentation. We propose a new prompting method that ensures the output text is unedited, is much more token-efficient, and is not limited by the context window of the model. We show that this outperforms existing non-prompting based approaches by comparing to our own existing method which uses SentenceBERT embeddings and cosine similarity.

% \vspace{-0.2em}