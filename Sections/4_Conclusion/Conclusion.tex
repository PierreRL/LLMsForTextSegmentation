% 4. Conclusion

Our work compares generative LLMs with methods which use BERT embeddings and cosine similarity for topic segmentations. We propose a new prompting method that is token-efficient and guarantees that outputs are unedited. We support the use of boundary similarity for evaluation. Results indicate that LLMs can be more effective segmenters where more nuanced segmentations are required. However, when the input is noisy or the segment boundaries are clear, BERT-based methods may be more reliable. Future work should involve a thorough comparison of different prompting methods and address highlighted issues with LLM outputs using our method. Lastly, larger human-annotated datasets should be constructed rather than relying on headings or concatenated paragraphs.